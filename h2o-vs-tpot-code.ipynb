{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55790423-e488-47b4-b4cc-7e7e76217d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/600 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9714285714285713\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9714285714285713\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9714285714285715\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9714285714285715\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9714285714285715\n",
      "\n",
      "Best pipeline: LogisticRegression(VarianceThreshold(RobustScaler(input_matrix), threshold=0.001), C=0.5, dual=False, penalty=l2)\n",
      "[1 1 0 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "### TPOT ###\n",
    "\n",
    "# Importing necessary tools and libraries\n",
    "import tpot\n",
    "from tpot import TPOTClassifier\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initializing our TPOT pipeline optimizer\n",
    "pipeline_optimizer = TPOTClassifier(generations=5, \n",
    "                                    verbosity=2, \n",
    "                                    config_dict=\"TPOT light\")\n",
    "\n",
    "# Loading a dataset for training\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "# Splitting our data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"data\"], \n",
    "                                                    data[\"target\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=data[\"target\"])\n",
    "\n",
    "# Training the AutoML algorithm\n",
    "pipeline_optimizer.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting class names\n",
    "y_pred = pipeline_optimizer.predict(X_test)\n",
    "\n",
    "# Viewing predictions\n",
    "print(y_pred[:10])\n",
    "\n",
    "# Exporting the pipeline's code\n",
    "pipeline_optimizer.export('tpot_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745fbc00-06ef-4a98-9f0a-2ec746a4f7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.301-b09, mixed mode)\n",
      "  Starting server from C:\\Users\\tigra\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\tigra\\AppData\\Local\\Temp\\tmp4oksfd45\n",
      "  JVM stdout: C:\\Users\\tigra\\AppData\\Local\\Temp\\tmp4oksfd45\\h2o_tigra_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\tigra\\AppData\\Local\\Temp\\tmp4oksfd45\\h2o_tigra_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Yerevan</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 15 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>h2ocluster</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.545 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>6</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Asia/Yerevan\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.7\n",
       "H2O_cluster_version_age:    1 month and 15 days\n",
       "H2O_cluster_name:           h2ocluster\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.545 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  6\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.9.5 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "AutoML progress: |\n",
      "17:41:34.466: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">         p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.000151923</td><td style=\"text-align: right;\">0.999848   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.00766983 </td><td style=\"text-align: right;\">0.99233    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">4.41217e-05</td><td style=\"text-align: right;\">0.999956   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.0243219  </td><td style=\"text-align: right;\">0.975678   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00631126 </td><td style=\"text-align: right;\">0.993689   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.517591   </td><td style=\"text-align: right;\">0.482409   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">4.28303e-05</td><td style=\"text-align: right;\">0.999957   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999843   </td><td style=\"text-align: right;\">0.000157158</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00032014 </td><td style=\"text-align: right;\">0.99968    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">4.75229e-05</td><td style=\"text-align: right;\">0.999952   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### H2O AutoML ###\n",
    "\n",
    "# Importing necessary tools\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initializing our H2O cluster\n",
    "h2o.init(name=\"h2ocluster\", nthreads=6)\n",
    "\n",
    "# Loading a dataset for training\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "# Splitting our data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"data\"], \n",
    "                                                    data[\"target\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=data[\"target\"])\n",
    "\n",
    "# Creating H2OFrame objects for train data\n",
    "train_features = h2o.H2OFrame(X_train, column_names=list(data[\"feature_names\"]))\n",
    "train_labels = h2o.H2OFrame(y_train, column_names=[\"target\"])\n",
    "\n",
    "# Creating H2OFrame objects for test data\n",
    "test_features = h2o.H2OFrame(X_test, column_names=list(data[\"feature_names\"]))\n",
    "test_labels = h2o.H2OFrame(y_test, column_names=[\"target\"])\n",
    "\n",
    "# Joining our features and labels\n",
    "train_frame = train_features.cbind(train_labels)\n",
    "test_frame = test_features.cbind(test_labels)    \n",
    "\n",
    "# Specifying feature and target names for training\n",
    "x = train_frame.columns\n",
    "y = \"target\"\n",
    "x.remove(y)\n",
    "\n",
    "# Converting labels to categoricals\n",
    "train_frame[y] = train_frame[y].asfactor()\n",
    "test_frame[y] = test_frame[y].asfactor()\n",
    "\n",
    "# Creating our AutoML object\n",
    "aml = H2OAutoML(seed=1, max_runtime_secs=300)\n",
    "\n",
    "# Training the AutoML object\n",
    "aml.train(x=x, y=y, training_frame=train_frame)\n",
    "\n",
    "# Obtaining the best model\n",
    "best_model = aml.leader # Equivalent to aml.get_best_model()\n",
    "\n",
    "# Doing inference with the best model\n",
    "predictions = best_model.predict(test_frame)\n",
    "\n",
    "# Viewing predictions\n",
    "print(predictions)\n",
    "\n",
    "# Saving our model\n",
    "model_path = h2o.save_model(model=best_model,   \n",
    "                            path=\"/tmp/leader_model\", \n",
    "                            force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
